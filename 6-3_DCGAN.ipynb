{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1lqKji35SZzxwDvpAgJ7JrRDp1C0IXwCz"
    },
    "executionInfo": {
     "elapsed": 611782,
     "status": "ok",
     "timestamp": 1741567739174,
     "user": {
      "displayName": "Dong-Chul Kim",
      "userId": "03756454252531288703"
     },
     "user_tz": 300
    },
    "id": "E46dZRemfPis",
    "outputId": "fc986128-d033-420f-f26c-3dd1a8a39ce7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# === Changes Applied ===\n",
    "# 1. Switched to BCEWithLogitsLoss and removed Sigmoid from Discriminator\n",
    "# 2. Moved fixed_noise outside the training loop for consistent epoch-to-epoch comparison\n",
    "\n",
    "\n",
    "# 1. Environment Setup and Hyperparameter Definition\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "num_epochs = 30\n",
    "z_dim = 100  # Dimension of the latent space\n",
    "\n",
    "# 2. Loading and Preprocessing the Dataset (FashionMNIST)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize pixel values to the range [-1, 1]\n",
    "])\n",
    "dataset = dsets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 3. Implementing the Generator Model for DCGAN (Using CNN)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, img_channels=1, feature_map_g=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # Input: (z_dim, 1, 1)\n",
    "            nn.ConvTranspose2d(z_dim, feature_map_g * 2, kernel_size=7, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(feature_map_g * 2),\n",
    "            nn.ReLU(True),\n",
    "            # Output: (feature_map_g*2, 7, 7)\n",
    "            nn.ConvTranspose2d(feature_map_g * 2, feature_map_g, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(feature_map_g),\n",
    "            nn.ReLU(True),\n",
    "            # Output: (feature_map_g, 14, 14)\n",
    "            nn.ConvTranspose2d(feature_map_g, img_channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh()  # Adjust output to the range [-1, 1]\n",
    "            # Final output: (img_channels, 28, 28)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# 4. Implementing the Discriminator Model for DCGAN (Using CNN)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels=1, feature_map_d=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # Input: (img_channels, 28, 28)\n",
    "            nn.Conv2d(img_channels, feature_map_d, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Output: (feature_map_d, 14, 14)\n",
    "            nn.Conv2d(feature_map_d, feature_map_d * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(feature_map_d * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Output: (feature_map_d*2, 7, 7)\n",
    "            nn.Conv2d(feature_map_d * 2, 1, kernel_size=7, stride=1, padding=0, bias=False),\n",
    "            # nn.Sigmoid() # REMOVED this line for BCEWithLogitsLoss\n",
    "            # CHANGED: Removed Sigmoid activation to use raw logits with BCEWithLogitsLoss\n",
    "            # Output: (1, 1, 1) which is then flattened to (batch, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x.view(-1, 1)\n",
    "\n",
    "# 5. Creating the Models and Allocating Them to the Device\n",
    "generator = Generator(z_dim=z_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# 6. Loss Function and Optimizers Setup\n",
    "#adversarial_loss = nn.BCELoss()\n",
    "adversarial_loss = nn.BCEWithLogitsLoss()  # Using raw logits for numerical stability\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# 7. Weight Initialization (Initialize all Convolution layers with a normal distribution: mean 0, std 0.02)\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "\n",
    "fixed_noise = torch.randn(25, z_dim, 1, 1, device=device)  #Moved here â€” constant visual reference\n",
    "\n",
    "# 8. Training Process\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (imgs, _) in enumerate(data_loader):\n",
    "        batch_size_i = imgs.size(0)\n",
    "\n",
    "        valid = torch.ones((batch_size_i, 1), device=device)\n",
    "        fake = torch.zeros((batch_size_i, 1), device=device)\n",
    "\n",
    "        real_imgs = imgs.to(device)\n",
    "\n",
    "        # ----- Train Generator -----\n",
    "        optimizer_G.zero_grad()\n",
    "        # Generate random noise in the shape (z_dim, 1, 1) from the latent space\n",
    "        z = torch.randn(batch_size_i, z_dim, 1, 1, device=device)\n",
    "        gen_imgs = generator(z)\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ----- Train Discriminator -----\n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        G_losses.append(g_loss.item())\n",
    "        D_losses.append(d_loss.item())\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"[Epoch {epoch+1}/{num_epochs}] [Batch {i}/{len(data_loader)}] [D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n",
    "\n",
    "    # Visualize generated images at the end of each epoch\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        #fixed_noise = torch.randn(25, z_dim, 1, 1, device=device)\n",
    "        gen_imgs = generator(fixed_noise)\n",
    "    generator.train()\n",
    "\n",
    "    gen_imgs = (gen_imgs + 1) / 2  # Convert from [-1,1] to [0,1]\n",
    "    grid = torchvision.utils.make_grid(gen_imgs, nrow=5, padding=2, normalize=False)\n",
    "    np_grid = grid.cpu().numpy().transpose((1, 2, 0))\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(np_grid)\n",
    "    plt.title(f\"Epoch {epoch+1}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize loss curves after training\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses, label=\"Generator Loss\")\n",
    "plt.plot(D_losses, label=\"Discriminator Loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPmfibvNmeaTDvDHH5TKA2d",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
